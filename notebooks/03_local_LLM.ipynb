{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPB01RBOfv9M3jxCys6DUm5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kavyajeetbora/nlp_doc/blob/master/notebooks/03_local_LLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting a local LLM\n",
        "\n",
        "How to choose the LLM model for text generation ?\n",
        "\n",
        "There are plently of models regularly been updated and open-sourced. You can check out the [hugging face leaderboard](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard)\n",
        "\n",
        "However the choice of LLM also depends on the hardware that is available in the local machine\n",
        "\n",
        "Also these models occupies large disk space. It is recommened to also look for [quantized version of these models](https://huggingface.co/TheBloke)"
      ],
      "metadata": {
        "id": "zTkNo_oJskwq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Checking our local GPU memory availability\n"
      ],
      "metadata": {
        "id": "lR0kfSNrsae6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FbcB_qCisZrh"
      },
      "outputs": [],
      "source": [
        "gpu_memory_bytes = torch.cuda.get_device_properties(0).total_memory\n",
        "gpu_memory_gb = round(gpu_memory_bytes / (2**30))\n",
        "print(f\"Available GPU memory: {gpu_memory_gb} GB\")"
      ]
    }
  ]
}